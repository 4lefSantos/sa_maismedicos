{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c2211d",
   "metadata": {},
   "source": [
    "# Análise preditiva do Programa Mais Médicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8930a3",
   "metadata": {},
   "source": [
    "O objetivo desse notebook é, a partir de dados do Programa Mais Médicos, aplicar métodos de Machine Learn para entender quais são as features (variáveis) que melhor explicam o churn, isto é, a decisão de um médico permanecer na cidade em que foi designado. Para isso, estruturamos o script em três etapas:\n",
    "\n",
    "**1. Pré-processamento:** A base será tratada de forma que possa ser utilizada para treinar o modelo.\n",
    "\n",
    "**2. Definição do modelo:** Definição do modelo preditivo com as melhores métricas.\n",
    "\n",
    "**3. Interpretação:** Explicação do modelo escolhido.\n",
    "\n",
    "Abaixo são carregados os pacotes que serão utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29d0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "import optuna\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0e788",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc92738",
   "metadata": {},
   "source": [
    "Iniciaremos carregando a base de dados e observando as variáveis presentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505f4acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'meses_no_local_alocado',\n",
       " 'churn',\n",
       " 'idade',\n",
       " 'anos_formacao',\n",
       " 'atuacao_previa_no_municipio',\n",
       " 'anos_atuacao_previa_no_municipio',\n",
       " 'media_vinculos_mes',\n",
       " 'Prorrogado',\n",
       " 'm_agente_saude',\n",
       " 'm_tec_aux_enf',\n",
       " 'm_enfermeiro',\n",
       " 'm_dentista',\n",
       " 'regiao_destino',\n",
       " 'populacao',\n",
       " 'porte',\n",
       " 'pib_percapita',\n",
       " 'variacao_pib',\n",
       " 'tx_pop_ocupada_2019',\n",
       " 'orcamento_saude',\n",
       " 'esgotamento_sanitario',\n",
       " 'taxa_homicidio',\n",
       " 'ideb_anosfinais',\n",
       " 'investimento_infraestrutura',\n",
       " 'equipamentos_esportivos',\n",
       " 'equipamentos_culturais',\n",
       " 'distancia_capital']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_completo = pd.read_csv(r\"C:\\Users\\alefs\\OneDrive\\Documentos\\LAPEI-CIGETS\\sa_maismedicos\\01_dados\\dados resultantes\\df_modelagem0303.csv\")\n",
    "\n",
    "list(df_completo.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9203e18f",
   "metadata": {},
   "source": [
    "Em seguida, removeremos algumas variáveis que não serão necessária e transformaremos a variável churn em uma dummy, com valor 0 se permanece e 1 se migrou. Além disso, os valores nulos serão substituídos por zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "295f1a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo = df_completo.drop(['Unnamed: 0',\n",
    "                               \"meses_no_local_alocado\",\n",
    "                               \"variacao_pib\",\n",
    "                               'm_dentista',\n",
    "                               'anos_formacao'],\n",
    "                              axis = 'columns')\n",
    "\n",
    "df_completo['churn'] = df_completo['churn'].map({'permanece': 0, 'migrou': 1})\n",
    "\n",
    "df_completo[['m_agente_saude', \n",
    "             'm_tec_aux_enf', \n",
    "             'm_enfermeiro']] = df_completo[['m_agente_saude',\n",
    "                                             'm_tec_aux_enf', \n",
    "                                             'm_enfermeiro']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce11099",
   "metadata": {},
   "source": [
    "A seguir, dividiremos a base em quatro dataframes com conjunto de variáveis distintos, observando a seguinte estrutura:\n",
    "\n",
    "**Modelo 1 (M1):** Variáveis a nível indivíduo.\n",
    "\n",
    "**Modelo 2 (M2):** Variáveis a nível indivíduo, vínculos de trabalho e estabelecimento.\n",
    "\n",
    "**Modelo 3 (M3):** Variáveis a nível indivíduo, vínculos de trabalho, estabelecimento e município.\n",
    "\n",
    "**Modelo 4 (M4):** Variáveis a nível indivíduo, vínculos de trabalho, estabelecimento, município e variável prorrogação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f160f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m1 = df_completo[['churn', 'idade', 'atuacao_previa_no_municipio' ,'anos_atuacao_previa_no_municipio',\n",
    "                   'regiao_destino']]\n",
    "\n",
    "df_m2 = df_completo[['churn', 'idade', 'atuacao_previa_no_municipio' ,'anos_atuacao_previa_no_municipio',\n",
    "                   'regiao_destino', 'media_vinculos_mes',  'm_agente_saude', 'm_tec_aux_enf', 'm_enfermeiro']]\n",
    "\n",
    "df_m3 = df_completo.drop(['Prorrogado'], axis = 'columns')\n",
    "\n",
    "df_m4 = df_completo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b41367f",
   "metadata": {},
   "source": [
    "Abaixo iremos definir uma função que realizará os seguintes tratamentos:\n",
    "\n",
    "- Substituição de valores faltantes pela mediana (quantitativas), e pela de maior frequência (categóricas);\n",
    "- Padronização pelo método Z-score;\n",
    "- Balanceamento com SMOTE;\n",
    "- Divisão dos dados em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03990ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_e_balancear(df):\n",
    "    \n",
    "    y = df[['churn']]\n",
    "    X = df.drop(columns = ['churn'])\n",
    "    \n",
    "    num_features = X.select_dtypes(include = ['int64', 'float64']).columns.tolist()\n",
    "    cat_features = X.select_dtypes(include = ['object', 'category']).columns.tolist()\n",
    "    \n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy = 'median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy = 'most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_pipeline, num_features),\n",
    "        ('cat', cat_pipeline, cat_features)\n",
    "    ])\n",
    "    \n",
    "    # Divisão dos dados em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 42)\n",
    "    \n",
    "    #Aplicar pré-processamento\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    #Aplicação do SMOTE para balanceamento\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    y_train = y_train.astype('int') # Garantir que y_train seja numérico\n",
    "    X_train_balanceado, y_train_balanceado = smote.fit_resample(X_train_processed, y_train)\n",
    "    \n",
    "    return X_train_balanceado, X_test_processed, y_train_balanceado, y_test, preprocessor, X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bead18",
   "metadata": {},
   "source": [
    "Por fim, aplicaremos a função nos dataframes referentes aos quatros conjuntos de variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f95392ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m1, X_test_m1, y_train_m1, y_test_m1, preprocessor_m1, X_train_raw1 = dividir_e_balancear(df_m1)\n",
    "X_train_m2, X_test_m2, y_train_m2, y_test_m2, preprocessor_m2, X_train_raw2 = dividir_e_balancear(df_m2)\n",
    "X_train_m3, X_test_m3, y_train_m3, y_test_m3, preprocessor_m3, X_train_raw3 = dividir_e_balancear(df_m3)\n",
    "X_train_m4, X_test_m4, y_train_m4, y_test_m4, preprocessor_m4, X_train_raw4 = dividir_e_balancear(df_m4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e4514",
   "metadata": {},
   "source": [
    "## Definição do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af27888",
   "metadata": {},
   "source": [
    "Abaixo iremos definir uma função que irá testar e avaliar um conjunto de 5 algoritmos (Logistic Regression, Decision Tree, Random Forest, XGBoost e LightGBM) com otimização dos hiperâmetros utilizando a biblioteca optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2a884bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state = 42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state = 42),\n",
    "    'Random Forest': RandomForestClassifier(random_state = 42),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state = 42 )\n",
    "}\n",
    "\n",
    "# Definir uma função objetivo para o Optuna\n",
    "def objective(trial, model_name, x_train, y_train):\n",
    "    #Definindo os hiperparâmetros dos modelos a ser otimizado\n",
    "    if model_name == 'Logistic Regression':\n",
    "        C = trial.suggest_loguniform('C', 0.01, 10)\n",
    "        model = LogisticRegression(C = C)\n",
    "        \n",
    "    elif model_name == 'Decision Tree':\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "        model = DecisionTreeClassifier(max_depth = max_depth)\n",
    "        \n",
    "    elif model_name == 'Random Forest':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 100, 500, step = 100)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "        min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                      random_state=42)\n",
    "        \n",
    "    elif model_name == 'XGBoost':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 100, 500, step=100)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 9)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1)\n",
    "        subsample = trial.suggest_float('subsample', 0.7, 1.0)\n",
    "        colsample_bytree = trial.suggest_float('colsample_bytree', 0.7, 1.0)\n",
    "        gamma = trial.suggest_float('gamma', 0, 0.5)\n",
    "        model = xgb.XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, subsample=subsample, colsample_bytree=colsample_bytree, gamma=gamma, use_label_encoder=False, eval_metric='logloss',\n",
    "                                 random_state=42)\n",
    "    \n",
    "    elif model_name == 'LightGBM':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 100, 500, step=100)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1)\n",
    "        num_leaves = trial.suggest_int('num_leaves', 20, 40)\n",
    "        min_child_samples = trial.suggest_int('min_child_samples', 10, 30)\n",
    "        model = lgb.LGBMClassifier(n_estimators=n_estimators, learning_rate=learning_rate, num_leaves=num_leaves, min_child_samples=min_child_samples,\n",
    "                                  random_state=42)\n",
    "        \n",
    "    #Treinando o modelo\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    #Obtendo a probabilidade da classe positiva (para calcular a ROC AUC)\n",
    "    y_prob = model.predict_proba(x_train)[:,1]\n",
    "    \n",
    "    #Calculando a ROC para a combinação de hiperparâmetros\n",
    "    roc_auc = roc_auc_score(y_train, y_prob)\n",
    "    \n",
    "    return model, roc_auc\n",
    "\n",
    "def treinando_avaliando_optuna(x_train, y_train, x_test, y_test):\n",
    "    best_models = {}\n",
    "    best_roc_auc = {}\n",
    "    \n",
    "    for name in models.keys():\n",
    "        print(f\"Treinando modelo com Optuna: {name}\")\n",
    "        \n",
    "        #Otimização dos hiperparâmetros com optuna\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "        study.optimize(lambda trial: objective(trial, name, x_train, y_train)[1], n_trials=10)\n",
    "        \n",
    "        #Obtendo o melhor modelo\n",
    "        best_model, best_roc = objective(study.best_trial, name, x_train, y_train)\n",
    "        best_models[name] = best_model\n",
    "        best_roc_auc[name] = best_roc\n",
    "        \n",
    "        print(f\"Melhores parâmetros para {name}: {study.best_params}\\n\")\n",
    "        \n",
    "    #Avaliação no conjunto de teste\n",
    "    results = []\n",
    "    for name, model in best_models.items():\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_prob = model.predict_proba(x_test)[:,1]\n",
    "        results.append({'Model': name,\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1 Score': f1_score(y_test, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_test, y_prob)          \n",
    "        })\n",
    "        \n",
    "    return results, best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d52de2",
   "metadata": {},
   "source": [
    "### Modelo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d184d",
   "metadata": {},
   "source": [
    "A seguir, iremos aplicar a função de treinamento e avaliação dos algoritmos no conjunto de variáveis M1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7858af26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 16:39:38,672] A new study created in memory with name: no-name-ec97d810-eff5-4fb6-b17b-9a1b6e57b791\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,684] Trial 0 finished with value: 0.7072463642659279 and parameters: {'C': 0.13292918943162169}. Best is trial 0 with value: 0.7072463642659279.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,697] Trial 1 finished with value: 0.7077190096952909 and parameters: {'C': 7.114476009343421}. Best is trial 1 with value: 0.7077190096952909.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,708] Trial 2 finished with value: 0.7078298130193905 and parameters: {'C': 1.5702970884055387}. Best is trial 2 with value: 0.7078298130193905.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,722] Trial 3 finished with value: 0.7078332756232686 and parameters: {'C': 0.6251373574521749}. Best is trial 3 with value: 0.7078332756232686.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,736] Trial 4 finished with value: 0.7059807825484765 and parameters: {'C': 0.02938027938703535}. Best is trial 3 with value: 0.7078332756232686.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,740] Trial 5 finished with value: 0.7059807825484765 and parameters: {'C': 0.029375384576328288}. Best is trial 3 with value: 0.7078332756232686.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,751] Trial 6 finished with value: 0.7047532894736842 and parameters: {'C': 0.014936568554617643}. Best is trial 3 with value: 0.7078332756232686.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,768] Trial 7 finished with value: 0.7078523199445983 and parameters: {'C': 3.9676050770529883}. Best is trial 7 with value: 0.7078523199445983.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,781] Trial 8 finished with value: 0.7078453947368422 and parameters: {'C': 0.6358358856676253}. Best is trial 7 with value: 0.7078523199445983.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,792] Trial 9 finished with value: 0.707779605263158 and parameters: {'C': 1.3311216080736887}. Best is trial 7 with value: 0.7078523199445983.\n",
      "C:\\Users\\alefs\\AppData\\Local\\Temp\\ipykernel_9156\\821483248.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  C = trial.suggest_loguniform('C', 0.01, 10)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[I 2025-03-10 16:39:38,801] A new study created in memory with name: no-name-4a99545f-d98b-40dd-b0b5-ae213217473a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 16:39:38,810] Trial 0 finished with value: 0.7365157548476453 and parameters: {'max_depth': 5}. Best is trial 0 with value: 0.7365157548476453.\n",
      "[I 2025-03-10 16:39:38,820] Trial 1 finished with value: 0.8162101800554017 and parameters: {'max_depth': 10}. Best is trial 1 with value: 0.8162101800554017.\n",
      "[I 2025-03-10 16:39:38,830] Trial 2 finished with value: 0.7839629501385041 and parameters: {'max_depth': 8}. Best is trial 1 with value: 0.8162101800554017.\n",
      "[I 2025-03-10 16:39:38,840] Trial 3 finished with value: 0.7647654085872577 and parameters: {'max_depth': 7}. Best is trial 1 with value: 0.8162101800554017.\n",
      "[I 2025-03-10 16:39:38,848] Trial 4 finished with value: 0.720340200831025 and parameters: {'max_depth': 4}. Best is trial 1 with value: 0.8162101800554017.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo com Optuna: Logistic Regression\n",
      "Melhores parâmetros para Logistic Regression: {'C': 3.9676050770529883}\n",
      "\n",
      "Treinando modelo com Optuna: Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 16:39:38,855] Trial 5 finished with value: 0.720340200831025 and parameters: {'max_depth': 4}. Best is trial 1 with value: 0.8162101800554017.\n",
      "[I 2025-03-10 16:39:38,866] Trial 6 finished with value: 0.7088495498614957 and parameters: {'max_depth': 3}. Best is trial 1 with value: 0.8162101800554017.\n",
      "[I 2025-03-10 16:39:38,874] Trial 7 finished with value: 0.8017529432132964 and parameters: {'max_depth': 9}. Best is trial 1 with value: 0.8162101800554017.\n",
      "[I 2025-03-10 16:39:38,883] Trial 8 finished with value: 0.7647654085872577 and parameters: {'max_depth': 7}. Best is trial 1 with value: 0.8162101800554017.\n",
      "[I 2025-03-10 16:39:38,890] Trial 9 finished with value: 0.7832409972299169 and parameters: {'max_depth': 8}. Best is trial 1 with value: 0.8162101800554017.\n",
      "[I 2025-03-10 16:39:38,900] A new study created in memory with name: no-name-ee50d175-0887-44f4-826a-f1c340a217d2\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para Decision Tree: {'max_depth': 10}\n",
      "\n",
      "Treinando modelo com Optuna: Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 16:39:39,250] Trial 0 finished with value: 0.8070715027700832 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 0 with value: 0.8070715027700832.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:39,654] Trial 1 finished with value: 0.729748095567867 and parameters: {'n_estimators': 300, 'max_depth': 4, 'min_samples_split': 3}. Best is trial 0 with value: 0.8070715027700832.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:39,820] Trial 2 finished with value: 0.8027605609418281 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 0 with value: 0.8070715027700832.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:40,340] Trial 3 finished with value: 0.7183405470914128 and parameters: {'n_estimators': 400, 'max_depth': 3, 'min_samples_split': 10}. Best is trial 0 with value: 0.8070715027700832.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:41,023] Trial 4 finished with value: 0.7302969182825485 and parameters: {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 3}. Best is trial 0 with value: 0.8070715027700832.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:41,170] Trial 5 finished with value: 0.7411694944598338 and parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 6}. Best is trial 0 with value: 0.8070715027700832.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:41,597] Trial 6 finished with value: 0.7419226108033241 and parameters: {'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 7}. Best is trial 0 with value: 0.8070715027700832.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:41,741] Trial 7 finished with value: 0.7414421745152355 and parameters: {'n_estimators': 100, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 0 with value: 0.8070715027700832.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:42,220] Trial 8 finished with value: 0.8143533587257618 and parameters: {'n_estimators': 300, 'max_depth': 9, 'min_samples_split': 3}. Best is trial 8 with value: 0.8143533587257618.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:42,665] Trial 9 finished with value: 0.7829354224376732 and parameters: {'n_estimators': 300, 'max_depth': 7, 'min_samples_split': 2}. Best is trial 8 with value: 0.8143533587257618.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "[I 2025-03-10 16:39:43,140] A new study created in memory with name: no-name-c78fab8c-eb99-4cfa-9521-e9d5b733f1ae\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:43,254] Trial 0 finished with value: 0.8270342797783934 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.07587945476302646, 'subsample': 0.8795975452591109, 'colsample_bytree': 0.7468055921327309, 'gamma': 0.07799726016810132}. Best is trial 0 with value: 0.8270342797783934.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:43,301] Trial 1 finished with value: 0.7806475069252079 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.0641003510568888, 'subsample': 0.9124217733388136, 'colsample_bytree': 0.7061753482887407, 'gamma': 0.48495492608099716}. Best is trial 0 with value: 0.8270342797783934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para Random Forest: {'n_estimators': 300, 'max_depth': 9, 'min_samples_split': 3}\n",
      "\n",
      "Treinando modelo com Optuna: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:43,448] Trial 2 finished with value: 0.7798450484764542 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.02636424704863906, 'subsample': 0.7550213529560301, 'colsample_bytree': 0.7912726728878613, 'gamma': 0.2623782158161189}. Best is trial 0 with value: 0.8270342797783934.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:43,564] Trial 3 finished with value: 0.8063616689750693 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.06506676052501416, 'subsample': 0.7418481581956126, 'colsample_bytree': 0.7876433945605654, 'gamma': 0.18318092164684585}. Best is trial 0 with value: 0.8270342797783934.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:43,725] Trial 4 finished with value: 0.8160612880886426 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.02797064039425238, 'subsample': 0.8542703315240835, 'colsample_bytree': 0.8777243706586128, 'gamma': 0.023225206359998862}. Best is trial 0 with value: 0.8270342797783934.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:43,842] Trial 5 finished with value: 0.7610690789473684 and parameters: {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.015854643368675158, 'subsample': 0.984665661176, 'colsample_bytree': 0.9896896099223678, 'gamma': 0.40419867405823057}. Best is trial 0 with value: 0.8270342797783934.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:43,900] Trial 6 finished with value: 0.7638850415512466 and parameters: {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.07158097238609412, 'subsample': 0.8320457481218804, 'colsample_bytree': 0.7366114704534336, 'gamma': 0.2475884550556351}. Best is trial 0 with value: 0.8270342797783934.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:43,964] Trial 7 finished with value: 0.7894070290858725 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.03329019834400153, 'subsample': 0.8987566853061946, 'colsample_bytree': 0.7935133228268233, 'gamma': 0.2600340105889054}. Best is trial 0 with value: 0.8270342797783934.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:44,042] Trial 8 finished with value: 0.7837179709141274 and parameters: {'n_estimators': 300, 'max_depth': 4, 'learning_rate': 0.09726261649881028, 'subsample': 0.9325398470083344, 'colsample_bytree': 0.9818496824692567, 'gamma': 0.4474136752138244}. Best is trial 0 with value: 0.8270342797783934.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:44,190] Trial 9 finished with value: 0.7916144390581716 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.017964325184672756, 'subsample': 0.7587948587257435, 'colsample_bytree': 0.7135681866731614, 'gamma': 0.16266516538163217}. Best is trial 0 with value: 0.8270342797783934.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:39:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-03-10 16:39:44,298] A new study created in memory with name: no-name-ea7d0123-e83a-4004-8eb0-c6bd309ae780\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "[I 2025-03-10 16:39:44,376] Trial 0 finished with value: 0.8119624307479224 and parameters: {'n_estimators': 200, 'learning_rate': 0.09556428757689246, 'num_leaves': 35, 'min_child_samples': 22}. Best is trial 0 with value: 0.8119624307479224.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "[I 2025-03-10 16:39:44,410] Trial 1 finished with value: 0.74900709833795 and parameters: {'n_estimators': 100, 'learning_rate': 0.02403950683025824, 'num_leaves': 21, 'min_child_samples': 28}. Best is trial 0 with value: 0.8119624307479224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros para XGBoost: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.07587945476302646, 'subsample': 0.8795975452591109, 'colsample_bytree': 0.7468055921327309, 'gamma': 0.07799726016810132}\n",
      "\n",
      "Treinando modelo com Optuna: LightGBM\n",
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "[I 2025-03-10 16:39:44,507] Trial 2 finished with value: 0.8042209141274238 and parameters: {'n_estimators': 400, 'learning_rate': 0.0737265320016441, 'num_leaves': 20, 'min_child_samples': 30}. Best is trial 0 with value: 0.8119624307479224.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "[I 2025-03-10 16:39:44,641] Trial 3 finished with value: 0.8107669667590027 and parameters: {'n_estimators': 500, 'learning_rate': 0.029110519961044856, 'num_leaves': 23, 'min_child_samples': 13}. Best is trial 0 with value: 0.8119624307479224.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "[I 2025-03-10 16:39:44,709] Trial 4 finished with value: 0.8077891274238227 and parameters: {'n_estimators': 200, 'learning_rate': 0.05722807884690141, 'num_leaves': 29, 'min_child_samples': 16}. Best is trial 0 with value: 0.8119624307479224.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "[I 2025-03-10 16:39:44,825] Trial 5 finished with value: 0.7958976800554016 and parameters: {'n_estimators': 400, 'learning_rate': 0.022554447458683766, 'num_leaves': 26, 'min_child_samples': 17}. Best is trial 0 with value: 0.8119624307479224.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "[I 2025-03-10 16:39:44,910] Trial 6 finished with value: 0.813601108033241 and parameters: {'n_estimators': 300, 'learning_rate': 0.08066583652537122, 'num_leaves': 24, 'min_child_samples': 20}. Best is trial 6 with value: 0.813601108033241.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "[I 2025-03-10 16:39:45,020] Trial 7 finished with value: 0.7826731301939056 and parameters: {'n_estimators': 300, 'learning_rate': 0.014180537144799797, 'num_leaves': 32, 'min_child_samples': 13}. Best is trial 6 with value: 0.813601108033241.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "[I 2025-03-10 16:39:45,066] Trial 8 finished with value: 0.7880159279778394 and parameters: {'n_estimators': 100, 'learning_rate': 0.0953996983528, 'num_leaves': 40, 'min_child_samples': 26}. Best is trial 6 with value: 0.813601108033241.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-10 16:39:45,140] Trial 9 finished with value: 0.7749939404432133 and parameters: {'n_estimators': 200, 'learning_rate': 0.018790490260574548, 'num_leaves': 34, 'min_child_samples': 19}. Best is trial 6 with value: 0.813601108033241.\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 760, number of negative: 760\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 153\n",
      "[LightGBM] [Info] Number of data points in the train set: 1520, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Melhores parâmetros para LightGBM: {'n_estimators': 300, 'learning_rate': 0.08066583652537122, 'num_leaves': 24, 'min_child_samples': 20}\n",
      "\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "0  Logistic Regression  0.664537   0.715736  0.742105  0.728682  0.692769\n",
      "4             LightGBM  0.629393   0.686869  0.715789  0.701031  0.660227\n",
      "3              XGBoost  0.613419   0.668293  0.721053  0.693671  0.652760\n",
      "2        Random Forest  0.594249   0.675978  0.636842  0.655827  0.643175\n",
      "1        Decision Tree  0.578275   0.661111  0.626316  0.643243  0.583697\n"
     ]
    }
   ],
   "source": [
    "results_m1, models_m1 = treinando_avaliando_optuna(X_train_m1, y_train_m1, X_test_m1, y_test_m1)\n",
    "results_m1_df = pd.DataFrame(results_m1)\n",
    "print(results_m1_df.sort_values(by = 'ROC AUC', ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee7070",
   "metadata": {},
   "source": [
    "Observa-se que o melhor modelo foi Logistic Regression com o valor ROC AUC de 0,692769.\n",
    "\n",
    "A seguir iremos salvar na variável best_model_m1 o melhor algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5489e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identificando o nome do algoritmo com a melhor ROC AUC\n",
    "best_model_name = results_m1_df.sort_values(by='ROC AUC', ascending=False).iloc[0]['Model']\n",
    "\n",
    "#Recuperando o algoritmo com base no nome do algoritmo\n",
    "best_model_m1 = models_m1[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ff5efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alefs\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor limiar: 0.4070379738637933 com F1 Score: 0.694815606627472\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Treine o modelo\n",
    "best_model_m1.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Calcular probabilidades e encontrar o melhor limiar baseado no F1 Score\n",
    "y_prob_train = best_model_m1.predict_proba(X_train_m1)[:, 1]\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_m1, y_prob_train)\n",
    "\n",
    "best_threshold, best_f1 = max(((threshold, f1_score(y_train_m1, (y_prob_train >= threshold).astype(int))) for threshold in thresholds), key=lambda x: x[1])\n",
    "\n",
    "print(f\"Melhor limiar: {best_threshold} com F1 Score: {best_f1}\")\n",
    "\n",
    "# Ajustar previsões no conjunto de teste\n",
    "y_pred_adjusted = (best_model_m1.predict_proba(X_test_m1)[:, 1] >= best_threshold).astype(int)\n",
    "\n",
    "# Matriz de Confusão\n",
    "cm_adjusted = confusion_matrix(y_test_m1, y_pred_adjusted)\n",
    "\n",
    "# Exibição da Matriz de Confusão\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_adjusted, annot=True, fmt='d', cmap='Blues', xticklabels=['Permanece', 'Migrou'], yticklabels=['Permanece', 'Migrou'])\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.title(f'Matriz de Confusão - Ajuste de Limiar ({best_model_name})')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
